"""
AI Agent Chat Interface - Streamlit page for conversational AI.
"""
from typing import Optional

import streamlit as st

from oracle_duckdb_sync.agent import SyncAgent
from oracle_duckdb_sync.agent.core.llm_client import LLMConfig
from oracle_duckdb_sync.agent.factory import AgentFactory
from oracle_duckdb_sync.config import load_config


def initialize_agent():
    """Initialize agent with all services and tools."""
    config = load_config()
    llm_config = LLMConfig(model="gpt-4o-mini")
    return AgentFactory.create_agent(config, llm_config)


def initialize_chat_state():
    """Initialize chat session state."""
    if 'chat_messages' not in st.session_state:
        st.session_state.chat_messages = []
    if 'agent' not in st.session_state:
        st.session_state.agent = initialize_agent()


def render_chat_message(role: str, content: str):
    """Render a single chat message."""
    with st.chat_message(role):
        st.markdown(content)


def stream_agent_response(
    agent: SyncAgent,
    prompt: str
) -> tuple[Optional[str], list[dict]]:
    """
    Agent streaming ì‘ë‹µì„ Streamlitì— ì‹¤ì‹œê°„ ë Œë”ë§.

    Args:
        agent: SyncAgent ì¸ìŠ¤í„´ìŠ¤
        prompt: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€

    Returns:
        tuple: (ì‘ë‹µ í…ìŠ¤íŠ¸, ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸)
    """
    tool_results = []

    with st.chat_message("assistant"):
        text_placeholder = st.empty()
        status_placeholder = st.empty()
        full_text = ""

        for chunk in agent.process_message_stream(prompt):
            if chunk.type == "text":
                full_text += chunk.content
                text_placeholder.markdown(full_text + "â–Œ")

            elif chunk.type == "tool_status":
                status_placeholder.info(f"ğŸ”§ {chunk.content}")

            elif chunk.type == "tool_result":
                tool_results.append(chunk.tool_result)
                status_placeholder.empty()

            elif chunk.type == "error":
                text_placeholder.error(f"âš ï¸ {chunk.error}")
                return None, []

            elif chunk.type == "done":
                text_placeholder.markdown(full_text)
                status_placeholder.empty()

    return full_text, tool_results


def main():
    st.set_page_config(
        page_title="Data Sync AI Assistant",
        page_icon="ğŸ¤–",
        layout="wide"
    )

    st.title("ğŸ¤– ë°ì´í„° ë™ê¸°í™” AI ì–´ì‹œìŠ¤í„´íŠ¸")
    st.caption("ë°ì´í„° ë™ê¸°í™” ë° ë¶„ì„ì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤.")

    initialize_chat_state()

    # Sidebar: Tool information and settings
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.chat_messages = []
            st.session_state.agent.reset_conversation()
            st.rerun()

        st.divider()

        st.subheader("ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥")
        st.markdown("""
        - **ë™ê¸°í™” ì‹œì‘**: "USERS í…Œì´ë¸” ë™ê¸°í™” í•´ì¤˜"
        - **ìƒíƒœ í™•ì¸**: "í˜„ì¬ ìƒíƒœ ì•Œë ¤ì¤˜"
        - **í…Œì´ë¸” ëª©ë¡**: "ì–´ë–¤ í…Œì´ë¸”ì´ ìˆì–´?"
        - **í†µê³„ ì¡°íšŒ**: "ORDERS í…Œì´ë¸” ëª‡ ê±´ì´ì•¼?"
        - **ë°ì´í„° ì¡°íšŒ**: "USERS í…Œì´ë¸” ë³´ì—¬ì¤˜"
        """)

        st.divider()

        st.subheader("ğŸ“Š ë“±ë¡ëœ ë„êµ¬")
        tools = st.session_state.agent.tools.list_tools()
        for tool in tools:
            st.markdown(f"- `{tool}`")

    # Display chat history
    for msg in st.session_state.chat_messages:
        render_chat_message(msg["role"], msg["content"])

    # Chat input
    if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
        # Display user message
        st.session_state.chat_messages.append({
            "role": "user",
            "content": prompt
        })
        render_chat_message("user", prompt)

        # Streaming ì‘ë‹µ ì²˜ë¦¬
        response_text, tool_results = stream_agent_response(
            st.session_state.agent,
            prompt
        )

        if response_text:
            st.session_state.chat_messages.append({
                "role": "assistant",
                "content": response_text
            })

            # Show tool results if any (expandable)
            if tool_results:
                with st.expander("ğŸ”§ ë„êµ¬ ì‹¤í–‰ ìƒì„¸"):
                    for result in tool_results:
                        st.json(result)

        st.rerun()


if __name__ == "__main__":
    main()
